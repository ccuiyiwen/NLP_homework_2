让我们逐个讨论你提到的每个方面：

### (1) 不同的主题个数对分类性能的影响
在主题模型中，主题的数量（T）是一个重要的超参数。较少的主题可能会导致模型无法捕捉到数据中的复杂关系，从而降低分类性能；而较多的主题可能会导致过拟合，同样降低性能。因此，应该根据具体数据的复杂程度和特征来选择合适的主题数量。

你可以通过在不同主题数量下训练LDA模型，并使用交叉验证来评估分类性能。观察在不同主题数量下的交叉验证得分，看是否存在最优的主题数量，以及在这个数量附近性能是否稳定。

### (2) 以词和以字为基本单元的分类结果差异
以词和以字为基本单元的主要区别在于特征表示的粒度。以词为基本单元时，模型能够考虑到词语的语义信息，更加抽象和语义丰富；而以字为基本单元时，特征表示更加细粒度，包含了更多的语法和形态信息。

通常情况下，以词为基本单元的模型能够更好地捕捉语义信息，因此在具有丰富语义的文本数据上可能表现更好。而以字为基本单元的模型可能更适用于处理语言形态上的任务，如语音识别或者文本生成。

你可以在两种基本单元下分别训练模型，并比较它们的分类性能，以及对于不同类型的文本数据哪一种效果更好。

### (3) 不同长度的文本对主题模型性能的影响
主题模型通常会受到文本长度的影响。较短的文本可能包含的信息较少，难以捕捉到主题之间的关联；而较长的文本可能会包含更多的语义信息，有助于提高模型性能。

你可以尝试在不同长度的文本上训练模型，并比较它们的性能表现。观察不同长度文本的分类性能，看是否存在明显的差异。此外，你还可以考虑调整主题模型的参数，以适应不同长度文本的特点，例如调整主题数量或者采用不同的文本预处理方法。

通过上述实验和讨论，你可以更全面地了解主题模型在不同情况下的性能表现和应用场景。